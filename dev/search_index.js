var documenterSearchIndex = {"docs":
[{"location":"#StructuralDDP.jl-Documentation-1","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"This package defines, solves and simulates discrete dynamic optimization problems with value function iteration. It features different options to add structure to the problem and provide information about its properties. A wide range of problems can be solved very fast this way.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The general workflow is to define a problem, solve it, simulate it, and then analyze it. The full code for an example is:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"using StructuralDDP\nprob = CapitalAdjustModel(nK=150, nz=15, ρ=0.5, σ=0.3, γ=2.)\nsol = solve(prob)\nsim = simulate(sol, nPeriods=50, nFirms=5)\ndf_sim = DataFrame(sim)\nusing Plots, StatPlots\n@df df_sim plot(:period, :state_1, group=:firm,\n    xlabel=\"years\", ylabel=\"capital stock\")","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"where the individual pieces are described below.","category":"page"},{"location":"#Step-1:-define-problem-1","page":"StructuralDDP.jl Documentation","title":"Step 1: define problem","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Each infinite-horizon dynamic maximization problem has an objective function as follows","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"mathbbE sum_t=0^infty beta^t r(s_t a_t)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"where s_t are the state variables and a_t the choice variable(s), r(s_t a_t) is the current reward and β is the discount factor.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The state variables evolve according to a transition function Phi(s_t a_t varepsilon_t+1) depending on (s_t a_t) and i.i.d shocks varepsilon_t+1. For a more formal definiton, see the QuantEcon lectures. We can write the problem in a recursive form:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"V(s) = max_a r(s a) + beta mathbbE V(s) \ntextwhere  s = Phi(s a varepsilon)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"where s and s correspond to the current state s_t and next period's state s_t+1, respectively.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We will solve a capital investment model with convex adjustment costs as an example. It is defined as follows:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"V(Kz) = max_i K^alpha e^z - i K - fracgamma2 i^2 K + beta mathbbE V(K z) \ntextwhere  K = (1-delta + i) K \nz = rho z + sigma varepsilon quad varepsilon sim mathcalN(01)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"where K is current and K next period's capital and i is the (net) capital investment rate. Capital depreciates at the rate delta. Investment i adds to the capital stock but takes a period to become productive. The parameter gamma determines the adjustment costs for investment, over and above the cost of capital. The productivity of capital is determined by z, which follows an AR(1) process with autocorrelation rho and volatility sigma. There are decreasing returns to scale for alpha  1, so there is an optimal scale of the firm depending on z. The problem of the firm is to choose the optimal scale for next period.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We set up the problem by defining the state and action space, the reward function, the transition function and the factor at which future rewards are discounted.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"using StructuralDDP, Distributions\n\n# CapitalAdjustModel\nβ = 0.9 # discount factor\nα = 0.67 # returns to scale parameter\nρ = 0.6 # persistence of producitivity\nσ = 0.3 # volatility of productivity\nδ = 0.15 # deprectiation rate of capital\nγ = 2.0 # convex adjustment cost parameter\n\n\n# define state and action space\nnz = 5 # number of nodes for z\nstdz = sqrt(σ^2/(1-ρ^2))\nminz = -3*stdz\nmaxz =  3*stdz\nvz = collect(LinRange(minz, maxz, nz))\n\nnK = 100 # number of nodes for K\nK_ss = α * exp(0.)/ ((1-β)/β*(1+γ*δ) + δ) ^ (1/(1-α)) # analytical steady state of K\nlog_K_min = 0.1 * log(K_ss)\nlog_K_max = 2 * log(K_ss)\nvK   = exp.(collect(LinRange(log_K_min, log_K_max, nK))) # log-spaced grid for K\n\nni = 100 # number of nodes for i\nvi = collect(LinRange(-0.5, 2., ni))\n\ntStateVectors = (vK, vz)\ntChoiceVectors = (vi,)\n\n\n# define reward and transition functions\nfunction reward(vStates, vChoices)\n    K, z = vStates # note how the order corresponds to tStateVectors\n    i = vChoices[1]\n    return K^α * exp(z) - i*K - γ/2 * i^2 * K\nend\n\nfunction transition(vStates, vChoices, vShocks)\n    K, z = vStates # note how the order corresponds to tStateVectors\n    i = vChoices[1]\n    Kprime = (1-δ+i)*K\n    zprime  = ρ*z + σ * vShocks[1]\n    return Kprime, zprime\nend\n\nshockdistribution = Normal() # one-dimensional standard normal shock\n\n\n# construct problem\nprob = DiscreteDynamicProblem(\n            tStateVectors,\n            tChoiceVectors,\n            reward,\n            transition,\n            shockdistribution,\n            β)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The DiscreteDynamicProblem constructor creates a problem instance. It is important that the order of the arguments in the reward function, transition function and DiscreteDynamicProblem are the same as in the example above.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The package supports any type of univariate shock distribution and multivariate-normal shock distributions. Distributions.jl contains the syntax for implementing different shock distributions.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Note that in the problem definition above, the transition of the state variables is a function of states, choices and shocks. The solver will integrate over a high dimension of variables when calculating expectations, which is rather slow. The problem options section explains how to reformulate a large family of problems including the one above to gain orders of magnitude speedup.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The definition of the discrete state and action space means that the problem is solved for each point in the state space, where there finite number of possible actions. When simulating the model, linear interpolation is used to approximate the solution between grid points. Note that the state space is strict - the state variables are always forced to stay within their bounds upper and lower bounds.","category":"page"},{"location":"#Step-2:-solve-problem-1","page":"StructuralDDP.jl Documentation","title":"Step 2: solve problem","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We can solve the model with the function solve, which returns the value and optimal policy for each point in the state-space.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sol = solve(prob)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The result of solve is a solution object. We can retreive the value function with value and the policy function with policy. For example, the value and policy for the fifth grid point of the K and the third grid point of z are:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"value(sol)[5, 3] # 18.9\npolicy(sol)[5, 3] # 0.611","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"If there are multiple choice variables then policy(sol) returns a tuple, so we would have to specify that we for example are interested in the second choice variable:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"policy(sol)[2][5, 3]","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The policy and value objects that are returned by default act as a continuous solution via an interpolation. We can access the interpolated values by treating them as functions, for example:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"policy(sol)(10.2, 0.5) # 0.273 = optimal policy for K = 10.2 and z = 0.5","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Note the difference between these: indexing with [i,j] is the policy at the (i,j)th grid point, while (K,z) is an interpolation for state (Kz). Also note that if an interpolation outside of the state grid is requested, then the value/policy at the closest grid points is returned instead.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The solver can be controlled using different options which are discribed in the Solver Options section. For example, we can tell the solver to precompute the reward for all different combinations of states and choices before starting the value function iteration:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sol = solve(prob; rewardcall=:pre)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Experimenting with the solver options is essential if one wants to solve the model as fast as possible.","category":"page"},{"location":"#Step-3:-simulate-1","page":"StructuralDDP.jl Documentation","title":"Step 3: simulate","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We can simulate a panel:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sim = simulate(sol, nPeriods = 60, nFirms = 100)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The function simulate returns a simulation object, from which we can retreive the simulated states, choices and value as individual arrays:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sim_states = states(sim)\nsim_policy = policy(sim)\nsim_val = value(sim)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We can convert the simulation object into an array with Array(sim). The order of the variables is states, choices and value (if requested).","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We can also convert the simulation object into a dataframe:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"df_sim = DataFrame(sim)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We can then use the dataframe to analyse the simulation, for example by plotting a histogram:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"using Plots\nhistogram(df_sim.state_1, xlabel=\"K\",legend=false)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"or the each firm's capital stock over time:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"using StatsPlots\n@df df_sim plot(:period, :state_1, group=:firm, xlabel=\"time\", ylabel=\"K\")","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"By default, all firms start with the same state variables in the simulation. The simulator options section contains more details about this and more sophisticated methods to intialize the simulation.","category":"page"},{"location":"#Problem-Options-1","page":"StructuralDDP.jl Documentation","title":"Problem Options","text":"","category":"section"},{"location":"#Lower-integration-dimension-for-speed-1","page":"StructuralDDP.jl Documentation","title":"Lower integration dimension for speed","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The solver must calculate expectations of future states. By default, it must integrate over all state variables, choice variables and shocks, i.e. s_t+1 = Phi(s_t a_t varepsilon_t+1). Many problems can be rewritten in a way such that we can integrate over fewer variables, which leads to orders of magnitude speedup.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The first step is to rewrite the problem such that the action is equal to the corresponding next period's state. In our example, the action a of the firm then is not the investment rate but simply next period's capital stock K.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"V(Kz) = max_a K^alpha e^z - i K - fracgamma2 i^2 K + beta mathbbE V(K z) \ni equiv fracaK - (1-delta) \ntextwhere  K = a \nz = rho z + sigma varepsilon quad varepsilon sim mathcalN(01)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"By separating endogenous and exogenous state variables, resp. K and z, this way, we can define the problem as follows:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"tStateVectors = (vK, vz)\ntChoiceVectors = (1,) # specify which state corresponds to the choice\nfunction transfunc(vStates, vChoices, vShocks)\n    z = vStateVars[2]\n    zprime  = ρ*z + σ * vShocks[1];\n    return  zprime # only integrate z\nend\nprob = DiscreteDynamicProblem(...,\n            transfunc,\n            tChoiceVectors;\n            intdim = :Separable) # specify the integration dimension","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We need to specify which state corresponds to the choice, only return z in the transition function and specify that our integration dimension is of the type :Separable.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"In our example however we can do even better if we tell the solver that the choice of Kprime does not affect the transition of z.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"tStateVectors = (vK, vz)\ntChoiceVectors = (1,)\nfunction transfunc(vStates, vShocks) # no choices as input\n    z = vStateVars[2]\n    zprime  = ρ*z + σ * vShocks[1];\n    return  zprime\nend\nprob = DiscreteDynamicProblem(...,\n            transfunc,\n            tChoiceVectors;\n            intdim = :Separable_States) # specify the integration dimension","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Note that the transition function only takes states and shocks as an input and that the integration dimension now is of the type :Separable_States. In our example however we can do even better if we tell the solver that also the endogenous state K does not affect the transition of z.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"function transfunc(vExogStates, vShocks)\n    z = vExogStates[1] # note the different index for z\n    zprime  = ρ*z + σ * vShocks[1];\n    return  zprime\nend\nprob = DiscreteDynamicProblem(...,\n            transfunc,\n            tChoiceVectors;\n            intdim = :Separable_ExogStates) # specify the integration dimension","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Note that the transition function only takes the exogenous states and shocks as an input and that the integration dimension now is of the type :Separable_ExogStates.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Summarizing he four different types of integration dimensions:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":":All - next period states as a function of states, actions and shocks, i.e. s = Phi(s a varepsilon). This formulation is the slowest and corresponds to the baseline example. In the background, the solver calls QuanEcon's ddp.jl.\n:Separable - next period exogenous states as a function of all states, actions and shocks, i.e. s_e = Phi(s a varepsilon).\n:Separable_States - next period exogenous states as a function of all states and shocks, i.e. s_e = Phi(s varepsilon).\n:Separable_ExogStates - next period exogenous states as a function of only exogenous states and shocks, i.e. s_e = Phi(s_e varepsilon).","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"For the solver to be fast one should use the lowest possible dimension possible. For all separable integration dimensions one must specify which state vector corresponds to the choice vector, i.e. tChoiceVectors = (1,). Important: when defining the state space tStateVectors, the endogenous state variable(s) must come before the exogenous variables.","category":"page"},{"location":"#Concise-notation-1","page":"StructuralDDP.jl Documentation","title":"Concise notation","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"In some problems one may only have one shock or one choice variable. In this case, one can write the reward- and transition functions more concisely in terms as numbers as inputs as opposed to vectors:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"function reward(vStateVars, Kprime)\n    (K, z) = vStateVars\n    capx = Kprime - (1-δ)*K\n    return K^α * exp(z) + γ/2*(capx/K- δ)^2 * K\nend\nfunction transition(z, shock)\n    return zprime  = ρ*z + σ * shock\nend","category":"page"},{"location":"#Solver-Options-1","page":"StructuralDDP.jl Documentation","title":"Solver Options","text":"","category":"section"},{"location":"#For-speed-1","page":"StructuralDDP.jl Documentation","title":"For speed","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"There are different options available which make solving the model faster. One should check whether one can lower the integration dimension of the problem first though, described in the problem options section.","category":"page"},{"location":"#Monotonicity-and-concavity-1","page":"StructuralDDP.jl Documentation","title":"Monotonicity and concavity","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"From experience, these two options can lead to orders of magnitude speedup.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The monotonicity keyword allows the solver to exploit the monotonicity of the choice of next period's state in the current state. Put differently, if s^d*_t+1 is the optimal choice for s^d*_t, then the optimal choice for s^d_t geq s^d*_t is s^d_t+1 geq s^d*_t+1 (keeping fixed the other state variables). The default is false.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The concavity keyword allows the solver to exploit the concavity of the value function in the choice of next period's state. Put differently, if V(s^d_t+1 s^d_t s^s_t)  V(s^d*_t+1 s^d_t s^s_t), then also V(s^d_t+1 s^d_t s^s_t)  V(s^d_t+1 s^d_t s^s_t) for any s^d_t+1  s^d_t+1. The default is false.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"A handy way to check whether the problem fulfils these conditions is the isapprox function. It checks whether two different solutions are (almost) identical:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sol = solve(prob; concavity=false)\nsol_conc = solve(prob; concavity=true)\nisapprox(sol, sol_conc; rtol=1e-4)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Note: monotonicity and concavity currently only work if the integration dimension is separable.","category":"page"},{"location":"#Prebuilding-the-reward-matrix-1","page":"StructuralDDP.jl Documentation","title":"Prebuilding the reward matrix","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The rewardcall keyword determines whether (part of) the reward for each state-action pair should be precomputed before the value function iteration. Prebuilding requires more memory but less computations during the VFI.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":":jit - the reward is calculated during the VFI whenever it is required, i.e. just in time. This requires little memory but more computations during the VFI. This is the default.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":":pre - precompute the reward for each possible combination of states and actions before the VFI. This requires more memory but less computations during the VFI.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":":pre_partial - precompute part of the reward before the VFI that only depends on states, but not choices. From experience, this option is the fastest when combined with monotonicity and concavity. To exploit this option, we must supply the inner and outer part of the reward function when defining the problem. The outer part is the same argument in DDP as the standard reward function and the partial reward function enters as a keyword arguement rewardfunc_partial. In the solver we must then specify that the reward should be partially precomputed.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"function reward(partial_reward, vStates, vChoices)\n    K = vStateVars[1]\n    Kprime = vChoices[1]\n    i = Kprime/K - (1-δ)\n    return partial_reward - γ/2*i^2 * K) - i*K\nend\nreward_partial(vStates) = vStates[1]^α * exp(vStates[2])\n\nprob = DiscreteDynamicProblem(\n    tStateVectors,\n    tChoiceVectors,\n    reward,\n    transition,\n    shockdistribution,\n    β;\n    rewardfunc_partial = reward_partial)\n\nsolve(prob; rewardcall = :pre_partial)","category":"page"},{"location":"#Transition-matrix-1","page":"StructuralDDP.jl Documentation","title":"Transition matrix","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The solver calculates a markov transition matrix from the transition function using quadrature methods. We can control the number of quadrature nodes for each shock as with the keyword argument numquadnodes. The default is [5].","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"It is also possible to supply your own transition matrix with the keyword argument mTransition:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"using QuantEcon: tauchen\nsol = solve(prob, mTransition = tauchen(nz, ρ, σ))","category":"page"},{"location":"#Miscellaneous-1","page":"StructuralDDP.jl Documentation","title":"Miscellaneous","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"epsilon: Value for epsilon-optimality. Determines how accurate the solution is. Default is 1e-3.\nmax_iter: Maximum number of iterations before stopping. Default is 500.\ndisp: whether to display number of iterations and epsilon-convergence during solving. Default is false.\ndisp_each_iter: wait how many iterations for displaying status during solving. Default is 10.","category":"page"},{"location":"#Simulator-Options-1","page":"StructuralDDP.jl Documentation","title":"Simulator Options","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The keyword get_value determines whether the simulator should also compute the value at the beginning of each time period. This takes more time. The default is get_value = false.","category":"page"},{"location":"#Initialization-1","page":"StructuralDDP.jl Documentation","title":"Initialization","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The default setting of how the initial state variables are drawn at t=0 is the burn-in method. Here, each firm starts with states that are the median values of the state space. The idea is to simulate the model for more periods than necessary and then only analyse the simulated values after 60 periods or so on, depending on the persistence in the model.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"There is also an option for more sophisticated initialization, where the initial endogenous state variables are chosen by the firm subject to a loss function and the exogenous ones are predetermined or random. In the example, we assume the initial state variables are determined as follows:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"V_0(z_0) = max_K_0 V(K_0z_0) - (1 + (1 + C0) * K_0 \ntextwhere  z_0 = sqrtfracsigma^21-rho^2 ε_0 \nε_0 sim mathcalN(01)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The initial productivity z_0 is drawn from a normal distribution. Depending on z_0, the firm chooses it's initial capital stock K_0 to maximize it's continuation value, accounting for the fact that there is a deadweight cost C_0 to acquire K_0. If C_0  0, then K_0 will be optimally chosen below it's steady state value.","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"We must code the following as an additional input when constucting DiscreteDynamicProblem:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"initprob(value, vChoices) = value - (1 + (1-β)/β + C0) * vChoices[1]\ninit(vShocks) = vShocks[1] * sqrt(σ^2 / (1-ρ^2)) # = z0\nprob = DiscreteDynamicProblem(...;\n    initializationproblem = initprob,\n    initializefunc = init,\n    shockdist_initial = Normal(),\n    tChoiceVectorsZero = (1,)) # which state variable does the firm choose at t=0","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"The solve function then also finds the optimal policy at t=0 when the problem is defined this way. We can access the solutions via:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"sol = solve(prob)\nvalue0(sol)[5] # initial value if z0 = fifth grid point\nvalue0(sol)(0.5) # initial value if z0 = 0.5\npolicy0(sol)[5] # initial policy K_0 if z0 = fifth grid point\npolicy0(sol)[5, 3] # initial policy K_0 if z0 = 0.5","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"Even if the initializationproblem is specified this way, there is still an option to resort to the burn-in method. The keyword argument initialize_exact controls whether the simulator should use the sophisticated method or not. The default is true.","category":"page"},{"location":"#Fixed-shock-draws-1","page":"StructuralDDP.jl Documentation","title":"Fixed shock draws","text":"","category":"section"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"It is also possible to simulate a model solution using an identical draw of shocks:","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"shocks = drawshocks(prob, nPeriods = 60, nFirms = 100)\nsim = simulate(sol, shocks)","category":"page"},{"location":"#","page":"StructuralDDP.jl Documentation","title":"StructuralDDP.jl Documentation","text":"This can be useful for doing comparative statics on the model parameters, and wants to be sure that the shocks do not change. Note: the draw of shocks refers to the supplied shock distribution in the problem defintion. If the shock distribution is parametrized, for example by its variance, then one should not do comparative statics on those parameters.","category":"page"}]
}
